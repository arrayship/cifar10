{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1mG9Zej18lPY7sZiQu18VVxwsqamVjQZS","authorship_tag":"ABX9TyMTx/s+hMMYiD0fUoe3boaO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PqJseZbdUcSZ","colab_type":"text"},"source":["main\n","- checkpoint and early stopping (stop when train loss decrease & val loss increase)\n","- save trained model\n","- compare model test performance\n","- check logger system of ignite (+ plot)\n","\n","models\n","- resnet\n","- efficientnet"]},{"cell_type":"markdown","metadata":{"id":"Qw7KzI-ywzDS","colab_type":"text"},"source":["## colab settings"]},{"cell_type":"code","metadata":{"id":"zT481u-xXJFB","colab_type":"code","colab":{}},"source":["import os\n","\n","prj_name = 'cifar-10'\n","prj_path = '/content/drive/My Drive/colab/study/image_classification/'\\\n","        + prj_name + '/'\n","os.chdir(prj_path + 'notebooks/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hq3OWTyviTQY","colab_type":"text"},"source":["## settings"]},{"cell_type":"code","metadata":{"id":"4lQ1Exrko3ht","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","import sys\n","\n","sys.path.append('..')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lpcd2kXHij01","colab_type":"text"},"source":["# main"]},{"cell_type":"code","metadata":{"id":"WBWOqpQzPLXe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":181},"executionInfo":{"status":"ok","timestamp":1593957675241,"user_tz":-540,"elapsed":9151,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"e67a3c0d-a49d-4bfe-b0ff-360ccdd648d2"},"source":["from importlib import import_module\n","\n","import torch\n","import torch.nn as nn\n","\n","!pip install pytorch-ignite\n","from ignite.metrics import Accuracy, Loss"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch-ignite\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/69/811516d26518a204568bfbbd97838cff9d7ef4370684dcab49c6e5f60c5d/pytorch_ignite-0.4.0.post1-py2.py3-none-any.whl (164kB)\n","\r\u001b[K     |██                              | 10kB 12.6MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 122kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 133kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 143kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 153kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 163kB 4.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.5.1+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.18.5)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.0.post1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1Agb8w7qoAXI","colab_type":"text"},"source":["#### VGG"]},{"cell_type":"code","metadata":{"id":"8Di7AahiQ123","colab_type":"code","colab":{}},"source":["# model settings\n","model_mpath = 'src.models.vgg'\n","model_name = 'VGG'\n","model_cfg = {'cfg': [[64], [128], [256, 256], [512, 512], [512, 512]],\n","        'batch_norm': True}\n","init_weights = True\n","\n","# dataset, dataloader settings\n","batch_size = 2500\n","\n","# train settings\n","loss_fn = nn.CrossEntropyLoss()\n","opt = torch.optim.Adam\n","lr = 0.00003\n","val_metrics = {'acc': Accuracy(), 'loss': Loss(loss_fn)}\n","device = 'cuda:0'\n","max_epochs = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nyGHTO07oFw2","colab_type":"text"},"source":["#### InceptionV1"]},{"cell_type":"code","metadata":{"id":"RD_sPBtHoJi0","colab_type":"code","colab":{}},"source":["# model settings\n","model_mpath = 'src.models.inception_v1'\n","model_name = 'InceptionV1'\n","model_cfg = [\n","        [{1: (0, 64), 3: (96, 128), 5: (16, 32), 'm': 32}, [False, 0, 0], None],\n","        [{1: (0, 128), 3: (128, 192), 5: (32, 96), 'm': 64}, [True, 3, 2], None],\n","        [{1: (0, 192), 3: (96, 208), 5: (16, 48), 'm': 64}, [False, 0, 0], None],\n","        [{1: (0, 160), 3: (112, 224), 5: (24, 64), 'm': 64}, [False, 0, 0], 'aux'],\n","        [{1: (0, 128), 3: (128, 256), 5: (24, 64), 'm': 64}, [False, 0, 0], None],\n","        [{1: (0, 112), 3: (144, 288), 5: (32, 64), 'm': 64}, [False, 0, 0], None],\n","        [{1: (0, 256), 3: (160, 320), 5: (32, 128), 'm': 128}, [True, 2, 2], 'aux'],\n","        [{1: (0, 256), 3: (160, 320), 5: (32, 128), 'm': 128}, [False, 0, 0], None],\n","        [{1: (0, 384), 3: (192, 384), 5: (48, 128), 'm': 128}, [False, 0, 0], 'final']\n","        ]\n","init_weights = True\n","\n","# dataset, dataloader settings\n","batch_size = 2500\n","\n","# train settings\n","class loss_cls(nn.Module):\n","    def __init__(self):\n","        super(loss_cls, self).__init__()\n","    def forward(self, inp, tar):\n","        loss = 0\n","        loss_fn = nn.CrossEntropyLoss()\n","        inps = inp.split(10, 1)\n","        for i, p in enumerate(inps):\n","            if i < len(inps) - 1:\n","                loss += 0.3 * loss_fn(p, tar)\n","            else:\n","                loss += 1.0 * loss_fn(p, tar)\n","        return loss\n","loss_fn = loss_cls()\n","opt = torch.optim.Adam\n","lr = 0.00003\n","val_metrics = {'acc': Accuracy(), 'loss': Loss(loss_fn)}\n","device = 'cuda:0'\n","max_epochs = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"80KsAgYYAEXa","colab_type":"text"},"source":["#### ResNet"]},{"cell_type":"code","metadata":{"id":"6D-Afz65AH4u","colab_type":"code","colab":{}},"source":["# model settings\n","model_mpath = 'src.models.resnet'\n","model_name = 'ResNet'\n","model_cfg = [\n","        [(3, 64), (3, 64)],\n","        [(3, 128), (3, 128)],\n","        [(3, 256), (3, 256)],\n","        [(3, 512), (3, 512)]\n","        ]\n","init_weights = True\n","\n","# dataset, dataloader settings\n","batch_size = 2500\n","\n","# train settings\n","loss_fn = nn.CrossEntropyLoss()\n","opt = torch.optim.Adam\n","lr = 0.00003\n","val_metrics = {'acc': Accuracy(), 'loss': Loss(loss_fn)}\n","device = 'cuda:0'\n","max_epochs = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIbsjN3qFi50","colab_type":"text"},"source":["## load data"]},{"cell_type":"code","metadata":{"id":"vCMbJwLAL5UP","colab_type":"code","colab":{}},"source":["from src.data.make_dataset import Cifar10BatchDataset\n","\n","dpath = '../data/raw/'\n","\n","train_folds = []\n","for i in range(1, 6):\n","    train_folds.append(torch.load(dpath + 'data_batch_' + str(i) + '.pt'))\n","test_set = torch.load(dpath + 'test_batch.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbsLM8z4XB5X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1593954598278,"user_tz":-540,"elapsed":26451,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"509259d0-6d4a-4098-9805-40624a6ae1c8"},"source":["from collections import Counter\n","\n","for train_fold in train_folds:\n","    print(sorted(Counter(s['label'] for s in train_fold).items()))\n","print(sorted(Counter(s['label'] for s in test_set).items()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[(0, 1005), (1, 974), (2, 1032), (3, 1016), (4, 999), (5, 937), (6, 1030), (7, 1001), (8, 1025), (9, 981)]\n","[(0, 984), (1, 1007), (2, 1010), (3, 995), (4, 1010), (5, 988), (6, 1008), (7, 1026), (8, 987), (9, 985)]\n","[(0, 994), (1, 1042), (2, 965), (3, 997), (4, 990), (5, 1029), (6, 978), (7, 1015), (8, 961), (9, 1029)]\n","[(0, 1003), (1, 963), (2, 1041), (3, 976), (4, 1004), (5, 1021), (6, 1004), (7, 981), (8, 1024), (9, 983)]\n","[(0, 1014), (1, 1014), (2, 952), (3, 1016), (4, 997), (5, 1025), (6, 980), (7, 977), (8, 1003), (9, 1022)]\n","[(0, 1000), (1, 1000), (2, 1000), (3, 1000), (4, 1000), (5, 1000), (6, 1000), (7, 1000), (8, 1000), (9, 1000)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8V8CmJvQWAV4","colab_type":"code","colab":{}},"source":["from torch.utils.data import ConcatDataset, DataLoader\n","\n","train_set = ConcatDataset([f for j, f in enumerate(train_folds) if j != 4])\n","val_set = train_folds[4]\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size,\n","        shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_set, batch_size=batch_size,\n","        shuffle=True, num_workers=2)\n","test_loader = DataLoader(test_set, batch_size=batch_size,\n","        shuffle=True, num_workers=2)\n","\n","del train_folds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"blvVm5EVLg-v","colab_type":"text"},"source":["## model construction"]},{"cell_type":"code","metadata":{"id":"-cWwjHvIGhV1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593960020109,"user_tz":-540,"elapsed":82908,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"57025977-c761-4ab3-cc98-2ab6fa8b4a59"},"source":["model_cls = getattr(\n","        import_module(model_mpath),\n","        model_name\n","        )\n","model = model_cls(model_cfg, init_weights=init_weights)\n","for b in model.named_children():\n","    print(b)\n","#=============================vgg, inception layers 사이에 relu 꼬박꼬박 껴있는지 확인해라========================"],"execution_count":null,"outputs":[{"output_type":"stream","text":["('B_000_000', InV1StartBlock(\n","  (B_000): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (B_001): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  (B_002): ReLU(inplace=True)\n","  (B_003): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","  (B_004): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","  (B_005): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  (B_006): ReLU(inplace=True)\n","  (B_007): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  (B_008): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n","  (B_009): ReLU(inplace=True)\n","  (B_010): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","))\n","('B_001_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_002_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","  (B_002): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n","))\n","('B_003_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_004_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_004_001', InV1ClfBlock(\n","  (B_000): AdaptiveAvgPool2d(output_size=(4, 4))\n","  (B_001): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","  (B_002): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (B_003): ReLU(inplace=True)\n","  (B_004): Flatten()\n","  (B_005): Linear(in_features=2048, out_features=1024, bias=True)\n","  (B_006): ReLU(inplace=True)\n","  (B_007): Dropout(p=0.7, inplace=False)\n","  (B_008): Linear(in_features=1024, out_features=10, bias=True)\n","))\n","('B_005_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_006_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_007_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","  (B_002): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n","))\n","('B_007_001', InV1ClfBlock(\n","  (B_000): AdaptiveAvgPool2d(output_size=(4, 4))\n","  (B_001): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n","  (B_002): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (B_003): ReLU(inplace=True)\n","  (B_004): Flatten()\n","  (B_005): Linear(in_features=2048, out_features=1024, bias=True)\n","  (B_006): ReLU(inplace=True)\n","  (B_007): Dropout(p=0.7, inplace=False)\n","  (B_008): Linear(in_features=1024, out_features=10, bias=True)\n","))\n","('B_008_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_009_000', InV1InceptBlock(\n","  (B_001_000): InV1InConvBlock(\n","    (B_000): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","  )\n","  (B_001_001): InV1InConvBlock(\n","    (B_000): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_002): InV1InConvBlock(\n","    (B_000): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n","    (B_001): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (B_004): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_005): ReLU(inplace=True)\n","  )\n","  (B_001_003): InV1InPoolBlock(\n","    (B_000): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n","    (B_001): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n","    (B_002): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_003): ReLU(inplace=True)\n","  )\n","))\n","('B_009_001', InV1ClfBlock(\n","  (B_000): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (B_001): Flatten()\n","  (B_002): Dropout(p=0.2, inplace=False)\n","  (B_003): Linear(in_features=832, out_features=10, bias=True)\n","))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_QqNtfBLCHm0","colab_type":"code","colab":{}},"source":["#============================ResNet=============================================\n","class RNConvBlock(nn.Module):\n","    \"\"\"\n","    cfg = [(ksize1, n_otpch1), (ksize2, n_otpch2), (ksize3, n_otpch3)]\n","    \"\"\"\n","    def __init__(self, n_inpch, cfg):\n","        super(RNConvBlock, self).__init__()\n","        self.blocks = []\n","        self.make_net(n_inpch, cfg)\n","\n","    def forward(self, x):\n","        for b in self.blocks:\n","            x = b(x)\n","        return x\n","\n","    def make_net(self, n_inpch, cfg):\n","        for i, (ksize, n_otpch) in enumerate(cfg):\n","            self.blocks.append(nn.Conv2d(n_inpch, n_otpch,\n","                    kernel_size=ksize, padding=(ksize // 2)))\n","            self.blocks.append(nn.BatchNorm2d(n_otpch))\n","            if i < len(cfg) - 1:\n","                self.blocks.append(nn.ReLU(True))\n","            n_inpch = n_otpch\n","        for i, b in enumerate(self.blocks):\n","            self.add_module('B_' + str(i).zfill(3), b)\n","\n","class RNResBlock(nn.Module):\n","    \"\"\"\n","    cfg = [(ksize1, n_otpch1), (ksize2, n_otpch2), (ksize3, n_otpch3)]\n","    \"\"\"\n","    def __init__(self, n_inpch, cfg):\n","        super(RNResBlock, self).__init__()\n","        self.blocks = [[]]\n","        self.make_net(n_inpch, cfg)\n","\n","    def forward(self, x):\n","        x = self.blocks[0][0](x) + self.blocks[0][1](x)\n","        x = self.blocks[1](x)\n","        return x\n","\n","    def make_net(self, n_inpch, cfg):\n","        self.blocks[0].append(nn.Identity())\n","        self.blocks[0].append(RNConvBlock(n_inpch, cfg))\n","        self.blocks.append(nn.ReLU(True))\n","        for i, b in enumerate(self.blocks[0], 1):\n","            self.add_module('B_000_' + str(i).zfill(3), b)\n","        self.add_module('B_001', self.blocks[1])\n","            \n","class RNClfBlock(nn.Module):\n","    def __init__(self, n_inpch, n_otp):\n","        super(RNClfBlock, self).__init__()\n","        self.blocks = []\n","        self.make_net(n_inpch, n_otp)\n","\n","    def forward(self, x):\n","        for b in self.blocks:\n","            x = b(x)\n","        return x\n","\n","    def make_net(self, n_inpch, n_otp):\n","        self.blocks.append(nn.AdaptiveAvgPool2d((1, 1)))\n","        self.blocks.append(nn.Flatten())\n","        self.blocks.append(nn.Linear(n_inpch, n_otp))\n","        for i, b in enumerate(self.blocks):\n","            self.add_module('B_' + str(i).zfill(3), b)\n","\n","class ResNet(nn.Module): #=========================시작부분 만들어라=======================\n","    def __init__(self, cfg, n_otp=10, init_weights=False):\n","        super(ResNet, self).__init__()\n","        self.blocks = []\n","        self.make_net(cfg, n_otp)\n","        if init_weights:\n","            self._initialize_weights()\n","\n","    def forward(self, x):\n","        for b in self.blocks:\n","            x = b(x)\n","        return  x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n","                        nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def make_net(self, cfg, n_otp):\n","        n_inpch = 3\n","        for c in cfg:\n","            self.blocks.append(RNResBlock(n_inpch, c))\n","            n_inpch = c[- 1][1]\n","        self.blocks.append(RNClfBlock(n_inpch, n_otp))\n","        for i, b in enumerate(self.blocks):\n","            self.add_module('B_' + str(i).zfill(3), b)\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bkAnLyxGSAK9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":899},"executionInfo":{"status":"ok","timestamp":1593958661474,"user_tz":-540,"elapsed":535,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"4ece6f0c-4096-4920-f7ad-5cff677a0535"},"source":["model = ResNet(model_cfg)\n","for b in model.named_children():\n","    print(b)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["('B_000', RNResBlock(\n","  (B_000_001): Identity()\n","  (B_000_002): RNConvBlock(\n","    (B_000): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_001): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (B_001): ReLU(inplace=True)\n","))\n","('B_001', RNResBlock(\n","  (B_000_001): Identity()\n","  (B_000_002): RNConvBlock(\n","    (B_000): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_001): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (B_001): ReLU(inplace=True)\n","))\n","('B_002', RNResBlock(\n","  (B_000_001): Identity()\n","  (B_000_002): RNConvBlock(\n","    (B_000): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_001): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (B_001): ReLU(inplace=True)\n","))\n","('B_003', RNResBlock(\n","  (B_000_001): Identity()\n","  (B_000_002): RNConvBlock(\n","    (B_000): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_001): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (B_002): ReLU(inplace=True)\n","    (B_003): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (B_004): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (B_001): ReLU(inplace=True)\n","))\n","('B_004', RNClfBlock(\n","  (B_000): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (B_001): Flatten()\n","  (B_002): Linear(in_features=512, out_features=10, bias=True)\n","))\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mw88rPC5Fizx","colab_type":"text"},"source":["## train"]},{"cell_type":"code","metadata":{"id":"LU3xOwEkEbPH","colab_type":"code","colab":{}},"source":["import torchvision # 이따 집에서 test해보자 얘도 60% 언저리에서 끝나는지\n","model = torchvision.models.vgg11(pretrained=False, progress=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"__D0Iqs8WAg3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"095796fd-608f-4347-ea6c-778d4469c847"},"source":["from src.models.train_model import train_net\n","\n","opt = opt(model.parameters(), lr)\n","\n","trainer = train_net(model, opt, loss_fn, val_metrics,\n","        train_loader, val_loader, device)\n","trainer.run(train_loader, max_epochs=max_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1\n","Train - acc: 0.10 loss: 2.46 \n","Val   - acc: 0.10 loss: 2.47 \n","Epoch 2\n","Train - acc: 0.10 loss: 2.49 \n","Val   - acc: 0.10 loss: 2.49 \n","Epoch 3\n","Train - acc: 0.12 loss: 2.32 \n","Val   - acc: 0.12 loss: 2.32 \n","Epoch 4\n","Train - acc: 0.16 loss: 2.34 \n","Val   - acc: 0.15 loss: 2.35 \n","Epoch 5\n","Train - acc: 0.14 loss: 2.31 \n","Val   - acc: 0.14 loss: 2.31 \n","Epoch 6\n","Train - acc: 0.16 loss: 2.26 \n","Val   - acc: 0.16 loss: 2.26 \n","Epoch 7\n","Train - acc: 0.20 loss: 2.09 \n","Val   - acc: 0.20 loss: 2.09 \n","Epoch 8\n","Train - acc: 0.22 loss: 2.03 \n","Val   - acc: 0.22 loss: 2.03 \n","Epoch 9\n","Train - acc: 0.26 loss: 1.94 \n","Val   - acc: 0.26 loss: 1.95 \n","Epoch 10\n","Train - acc: 0.29 loss: 1.85 \n","Val   - acc: 0.29 loss: 1.86 \n","Epoch 11\n","Train - acc: 0.32 loss: 1.78 \n","Val   - acc: 0.32 loss: 1.78 \n","Epoch 12\n","Train - acc: 0.34 loss: 1.72 \n","Val   - acc: 0.34 loss: 1.73 \n","Epoch 13\n","Train - acc: 0.37 loss: 1.66 \n","Val   - acc: 0.37 loss: 1.67 \n","Epoch 14\n","Train - acc: 0.39 loss: 1.60 \n","Val   - acc: 0.39 loss: 1.62 \n","Epoch 15\n","Train - acc: 0.41 loss: 1.57 \n","Val   - acc: 0.41 loss: 1.59 \n","Epoch 16\n","Train - acc: 0.43 loss: 1.50 \n","Val   - acc: 0.43 loss: 1.53 \n","Epoch 17\n","Train - acc: 0.44 loss: 1.50 \n","Val   - acc: 0.44 loss: 1.53 \n","Epoch 18\n","Train - acc: 0.47 loss: 1.43 \n","Val   - acc: 0.46 loss: 1.46 \n","Epoch 19\n","Train - acc: 0.48 loss: 1.41 \n","Val   - acc: 0.47 loss: 1.44 \n","Epoch 20\n","Train - acc: 0.49 loss: 1.39 \n","Val   - acc: 0.48 loss: 1.42 \n","Epoch 21\n","Train - acc: 0.48 loss: 1.41 \n","Val   - acc: 0.47 loss: 1.44 \n","Epoch 22\n","Train - acc: 0.51 loss: 1.34 \n","Val   - acc: 0.50 loss: 1.37 \n","Epoch 23\n","Train - acc: 0.49 loss: 1.37 \n","Val   - acc: 0.48 loss: 1.41 \n","Epoch 24\n","Train - acc: 0.51 loss: 1.33 \n","Val   - acc: 0.50 loss: 1.37 \n","Epoch 25\n","Train - acc: 0.53 loss: 1.29 \n","Val   - acc: 0.51 loss: 1.34 \n","Epoch 26\n","Train - acc: 0.53 loss: 1.28 \n","Val   - acc: 0.52 loss: 1.33 \n","Epoch 27\n","Train - acc: 0.55 loss: 1.24 \n","Val   - acc: 0.53 loss: 1.29 \n","Epoch 28\n","Train - acc: 0.55 loss: 1.23 \n","Val   - acc: 0.53 loss: 1.29 \n","Epoch 29\n","Train - acc: 0.57 loss: 1.19 \n","Val   - acc: 0.55 loss: 1.25 \n","Epoch 30\n","Train - acc: 0.57 loss: 1.18 \n","Val   - acc: 0.55 loss: 1.25 \n","Epoch 31\n","Train - acc: 0.58 loss: 1.16 \n","Val   - acc: 0.55 loss: 1.23 \n","Epoch 32\n","Train - acc: 0.58 loss: 1.15 \n","Val   - acc: 0.56 loss: 1.23 \n","Epoch 33\n","Train - acc: 0.59 loss: 1.13 \n","Val   - acc: 0.57 loss: 1.20 \n","Epoch 34\n","Train - acc: 0.59 loss: 1.13 \n","Val   - acc: 0.56 loss: 1.20 \n","Epoch 35\n","Train - acc: 0.59 loss: 1.11 \n","Val   - acc: 0.57 loss: 1.19 \n","Epoch 36\n","Train - acc: 0.59 loss: 1.13 \n","Val   - acc: 0.56 loss: 1.21 \n","Epoch 37\n","Train - acc: 0.60 loss: 1.10 \n","Val   - acc: 0.58 loss: 1.19 \n","Epoch 38\n","Train - acc: 0.59 loss: 1.12 \n","Val   - acc: 0.56 loss: 1.21 \n","Epoch 39\n","Train - acc: 0.60 loss: 1.11 \n","Val   - acc: 0.57 loss: 1.21 \n","Epoch 40\n","Train - acc: 0.60 loss: 1.11 \n","Val   - acc: 0.57 loss: 1.21 \n","Epoch 41\n","Train - acc: 0.61 loss: 1.07 \n","Val   - acc: 0.58 loss: 1.18 \n","Epoch 42\n","Train - acc: 0.62 loss: 1.06 \n","Val   - acc: 0.58 loss: 1.16 \n","Epoch 43\n","Train - acc: 0.62 loss: 1.03 \n","Val   - acc: 0.59 loss: 1.14 \n","Epoch 44\n","Train - acc: 0.57 loss: 1.15 \n","Val   - acc: 0.54 loss: 1.27 \n","Epoch 45\n","Train - acc: 0.64 loss: 1.00 \n","Val   - acc: 0.60 loss: 1.12 \n","Epoch 46\n","Train - acc: 0.63 loss: 1.01 \n","Val   - acc: 0.59 loss: 1.14 \n","Epoch 47\n","Train - acc: 0.64 loss: 0.99 \n","Val   - acc: 0.60 loss: 1.12 \n","Epoch 48\n","Train - acc: 0.64 loss: 0.99 \n","Val   - acc: 0.60 loss: 1.13 \n","Epoch 49\n","Train - acc: 0.64 loss: 0.98 \n","Val   - acc: 0.60 loss: 1.13 \n","Epoch 50\n","Train - acc: 0.65 loss: 0.97 \n","Val   - acc: 0.60 loss: 1.12 \n","Epoch 51\n","Train - acc: 0.66 loss: 0.93 \n","Val   - acc: 0.61 loss: 1.09 \n","Epoch 52\n","Train - acc: 0.66 loss: 0.93 \n","Val   - acc: 0.61 loss: 1.09 \n","Epoch 53\n","Train - acc: 0.67 loss: 0.92 \n","Val   - acc: 0.61 loss: 1.09 \n","Epoch 54\n","Train - acc: 0.64 loss: 0.99 \n","Val   - acc: 0.60 loss: 1.16 \n","Epoch 55\n","Train - acc: 0.67 loss: 0.91 \n","Val   - acc: 0.61 loss: 1.09 \n","Epoch 56\n","Train - acc: 0.68 loss: 0.89 \n","Val   - acc: 0.62 loss: 1.08 \n","Epoch 57\n","Train - acc: 0.68 loss: 0.90 \n","Val   - acc: 0.61 loss: 1.09 \n","Epoch 58\n","Train - acc: 0.67 loss: 0.92 \n","Val   - acc: 0.61 loss: 1.11 \n","Epoch 59\n","Train - acc: 0.66 loss: 0.93 \n","Val   - acc: 0.59 loss: 1.14 \n","Epoch 60\n","Train - acc: 0.69 loss: 0.87 \n","Val   - acc: 0.62 loss: 1.09 \n","Epoch 61\n","Train - acc: 0.69 loss: 0.88 \n","Val   - acc: 0.62 loss: 1.09 \n","Epoch 62\n","Train - acc: 0.70 loss: 0.84 \n","Val   - acc: 0.62 loss: 1.06 \n","Epoch 63\n","Train - acc: 0.71 loss: 0.81 \n","Val   - acc: 0.63 loss: 1.04 \n","Epoch 64\n","Train - acc: 0.70 loss: 0.84 \n","Val   - acc: 0.62 loss: 1.08 \n","Epoch 65\n","Train - acc: 0.71 loss: 0.80 \n","Val   - acc: 0.63 loss: 1.04 \n","Epoch 66\n","Train - acc: 0.72 loss: 0.79 \n","Val   - acc: 0.64 loss: 1.04 \n","Epoch 67\n","Train - acc: 0.72 loss: 0.77 \n","Val   - acc: 0.63 loss: 1.04 \n","Epoch 68\n","Train - acc: 0.64 loss: 0.99 \n","Val   - acc: 0.57 loss: 1.25 \n","Epoch 69\n","Train - acc: 0.71 loss: 0.81 \n","Val   - acc: 0.63 loss: 1.06 \n","Epoch 70\n","Train - acc: 0.73 loss: 0.77 \n","Val   - acc: 0.64 loss: 1.04 \n","Epoch 71\n","Train - acc: 0.72 loss: 0.77 \n","Val   - acc: 0.64 loss: 1.05 \n","Epoch 72\n","Train - acc: 0.72 loss: 0.78 \n","Val   - acc: 0.63 loss: 1.07 \n","Epoch 73\n","Train - acc: 0.74 loss: 0.74 \n","Val   - acc: 0.64 loss: 1.04 \n","Epoch 74\n","Train - acc: 0.69 loss: 0.84 \n","Val   - acc: 0.61 loss: 1.13 \n","Epoch 75\n","Train - acc: 0.74 loss: 0.74 \n","Val   - acc: 0.64 loss: 1.05 \n","Epoch 76\n","Train - acc: 0.74 loss: 0.72 \n","Val   - acc: 0.64 loss: 1.04 \n","Epoch 77\n","Train - acc: 0.75 loss: 0.70 \n","Val   - acc: 0.64 loss: 1.04 \n","Epoch 78\n","Train - acc: 0.75 loss: 0.70 \n","Val   - acc: 0.64 loss: 1.05 \n","Epoch 79\n","Train - acc: 0.76 loss: 0.69 \n","Val   - acc: 0.64 loss: 1.02 \n","Epoch 80\n","Train - acc: 0.75 loss: 0.70 \n","Val   - acc: 0.64 loss: 1.04 \n","Epoch 81\n","Train - acc: 0.77 loss: 0.66 \n","Val   - acc: 0.65 loss: 1.02 \n","Epoch 82\n","Train - acc: 0.77 loss: 0.66 \n","Val   - acc: 0.65 loss: 1.04 \n","Epoch 83\n","Train - acc: 0.78 loss: 0.64 \n","Val   - acc: 0.65 loss: 1.02 \n","Epoch 84\n","Train - acc: 0.76 loss: 0.67 \n","Val   - acc: 0.64 loss: 1.06 \n","Epoch 85\n","Train - acc: 0.77 loss: 0.65 \n","Val   - acc: 0.65 loss: 1.05 \n","Epoch 86\n","Train - acc: 0.78 loss: 0.63 \n","Val   - acc: 0.65 loss: 1.04 \n","Epoch 87\n","Train - acc: 0.78 loss: 0.61 \n","Val   - acc: 0.65 loss: 1.04 \n","Epoch 88\n","Train - acc: 0.76 loss: 0.68 \n","Val   - acc: 0.64 loss: 1.10 \n","Epoch 89\n","Train - acc: 0.74 loss: 0.72 \n","Val   - acc: 0.63 loss: 1.09 \n","Epoch 90\n","Train - acc: 0.78 loss: 0.64 \n","Val   - acc: 0.65 loss: 1.04 \n","Epoch 91\n","Train - acc: 0.79 loss: 0.59 \n","Val   - acc: 0.65 loss: 1.04 \n","Epoch 92\n","Train - acc: 0.79 loss: 0.59 \n","Val   - acc: 0.65 loss: 1.05 \n","Epoch 93\n","Train - acc: 0.81 loss: 0.56 \n","Val   - acc: 0.66 loss: 1.03 \n","Epoch 94\n","Train - acc: 0.80 loss: 0.56 \n","Val   - acc: 0.65 loss: 1.05 \n","Epoch 95\n","Train - acc: 0.80 loss: 0.58 \n","Val   - acc: 0.64 loss: 1.08 \n","Epoch 96\n","Train - acc: 0.78 loss: 0.62 \n","Val   - acc: 0.64 loss: 1.13 \n","Epoch 97\n","Train - acc: 0.79 loss: 0.61 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CJYQoYeFWApV","colab_type":"text"},"source":["## Test"]},{"cell_type":"code","metadata":{"id":"Er2I72bjiJXe","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45miuSY_iJiQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593932283684,"user_tz":-540,"elapsed":632,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"8900f0c9-026d-4586-9b92-1a3d6a4f752b"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'asd12'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"ZsuAz94ziJqZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FocWjZXrw6sb","colab_type":"code","colab":{}},"source":["from src.models.vgg import VGG\n","\n","vgg11_cfg = [[64], [128], [256, 256], [512, 512], [512, 512]]\n","vgg11 = VGG(vgg11_cfg)\n","for b in vgg11.named_children():\n","    print(b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-X2E4ChZLuSl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1593504183831,"user_tz":-540,"elapsed":595517,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"16670a3b-4fe7-41f1-acc6-b24d8898c2cc"},"source":["# 수동으로 다 짜는 뻘짓이였다.\n","\n","from src.models.train_model import train_net\n","\n","from torch.utils.data import ConcatDataset, DataLoader\n","from torch.optim import Adam\n","import matplotlib.pyplot as plt\n","\n","loss_fn = nn.CrossEntropyLoss()\n","device = 'cuda:0'\n","\n","fig, ax = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(30, 10))\n","test_loader = DataLoader(test_set, batch_size=64,\n","        shuffle=True, num_workers=2)\n","fold_models = []\n","for i in range(5):\n","    # ====================random state, vgg11 copy for each fold\n","    train_set = ConcatDataset([f for j, f in enumerate(train_folds) if j != i])\n","    val_set = train_folds[i]\n","    train_loader = DataLoader(train_set, batch_size=5000,\n","            shuffle=True, num_workers=2)\n","    val_loader = DataLoader(val_set, batch_size=5000,\n","            shuffle=True, num_workers=2)\n","\n","    opt = Adam(vgg11.parameters(), lr=0.03)\n","    tl, ta, vl, va = train_net(vgg11, opt, loss_fn, 50,\n","            train_loader, val_loader, device, ax)\n","\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0: 100%|██████████| 8/8 [00:10<00:00,  1.25s/it]\n","1:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.10, v: 0.10\n"],"name":"stdout"},{"output_type":"stream","text":["1: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n","2:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.10, v: 0.10\n"],"name":"stdout"},{"output_type":"stream","text":["2: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","3:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.10, v: 0.10\n"],"name":"stdout"},{"output_type":"stream","text":["3: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","4:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.12, v: 0.15\n"],"name":"stdout"},{"output_type":"stream","text":["4: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","5:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.11, v: 0.12\n"],"name":"stdout"},{"output_type":"stream","text":["5: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","6:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.13, v: 0.14\n"],"name":"stdout"},{"output_type":"stream","text":["6: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","7:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.14, v: 0.15\n"],"name":"stdout"},{"output_type":"stream","text":["7: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","8:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.15, v: 0.15\n"],"name":"stdout"},{"output_type":"stream","text":["8: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","9:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.16, v: 0.18\n"],"name":"stdout"},{"output_type":"stream","text":["9: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","10:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.17, v: 0.19\n"],"name":"stdout"},{"output_type":"stream","text":["10: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","11:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.18, v: 0.19\n"],"name":"stdout"},{"output_type":"stream","text":["11: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","12:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.19, v: 0.21\n"],"name":"stdout"},{"output_type":"stream","text":["12: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","13:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.17, v: 0.18\n"],"name":"stdout"},{"output_type":"stream","text":["13: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","14:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.18, v: 0.19\n"],"name":"stdout"},{"output_type":"stream","text":["14: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","15:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.16, v: 0.19\n"],"name":"stdout"},{"output_type":"stream","text":["15: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","16:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.19, v: 0.20\n"],"name":"stdout"},{"output_type":"stream","text":["16: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","17:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.20, v: 0.21\n"],"name":"stdout"},{"output_type":"stream","text":["17: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","18:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.21, v: 0.22\n"],"name":"stdout"},{"output_type":"stream","text":["18: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","19:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.21, v: 0.22\n"],"name":"stdout"},{"output_type":"stream","text":["19: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","20:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.21, v: 0.20\n"],"name":"stdout"},{"output_type":"stream","text":["20: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","21:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.20, v: 0.21\n"],"name":"stdout"},{"output_type":"stream","text":["21: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","22:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.20, v: 0.20\n"],"name":"stdout"},{"output_type":"stream","text":["22: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","23:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.21, v: 0.22\n"],"name":"stdout"},{"output_type":"stream","text":["23: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","24:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.22, v: 0.22\n"],"name":"stdout"},{"output_type":"stream","text":["24: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","25:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.22, v: 0.24\n"],"name":"stdout"},{"output_type":"stream","text":["25: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","26:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.23, v: 0.24\n"],"name":"stdout"},{"output_type":"stream","text":["26: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","27:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.24, v: 0.24\n"],"name":"stdout"},{"output_type":"stream","text":["27: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","28:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.25, v: 0.25\n"],"name":"stdout"},{"output_type":"stream","text":["28: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","29:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.26, v: 0.26\n"],"name":"stdout"},{"output_type":"stream","text":["29: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","30:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.26, v: 0.27\n"],"name":"stdout"},{"output_type":"stream","text":["30: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","31:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.27, v: 0.27\n"],"name":"stdout"},{"output_type":"stream","text":["31: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n","32:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.26, v: 0.26\n"],"name":"stdout"},{"output_type":"stream","text":["32: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","33:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.26, v: 0.26\n"],"name":"stdout"},{"output_type":"stream","text":["33: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","34:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.26, v: 0.28\n"],"name":"stdout"},{"output_type":"stream","text":["34: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n","35:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.28, v: 0.30\n"],"name":"stdout"},{"output_type":"stream","text":["35: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n","36:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.29, v: 0.30\n"],"name":"stdout"},{"output_type":"stream","text":["36: 100%|██████████| 8/8 [00:10<00:00,  1.25s/it]\n","37:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.30, v: 0.29\n"],"name":"stdout"},{"output_type":"stream","text":["37: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","38:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.29, v: 0.27\n"],"name":"stdout"},{"output_type":"stream","text":["38: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","39:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.29, v: 0.31\n"],"name":"stdout"},{"output_type":"stream","text":["39: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","40:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.30, v: 0.31\n"],"name":"stdout"},{"output_type":"stream","text":["40: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","41:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.31, v: 0.31\n"],"name":"stdout"},{"output_type":"stream","text":["41: 100%|██████████| 8/8 [00:09<00:00,  1.25s/it]\n","42:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.31, v: 0.31\n"],"name":"stdout"},{"output_type":"stream","text":["42: 100%|██████████| 8/8 [00:09<00:00,  1.24s/it]\n","43:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.32, v: 0.33\n"],"name":"stdout"},{"output_type":"stream","text":["43: 100%|██████████| 8/8 [00:10<00:00,  1.26s/it]\n","44:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.33, v: 0.34\n"],"name":"stdout"},{"output_type":"stream","text":["44: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n","45:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.34, v: 0.35\n"],"name":"stdout"},{"output_type":"stream","text":["45: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n","46:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.34, v: 0.35\n"],"name":"stdout"},{"output_type":"stream","text":["46: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n","47:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.34, v: 0.35\n"],"name":"stdout"},{"output_type":"stream","text":["47: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n","48:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.34, v: 0.35\n"],"name":"stdout"},{"output_type":"stream","text":["48: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n","49:   0%|          | 0/8 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["t: 0.35, v: 0.37\n"],"name":"stdout"},{"output_type":"stream","text":["49: 100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["t: 0.35, v: 0.37\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a7fb4b0b4a25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 2160x720 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"4NQ5P36ae5e7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8jLi_DJ4dwL","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn.functional as F\n","input = torch.randn(3, 5, requires_grad=True)\n","target = torch.randint(5, (3,), dtype=torch.int64)\n","loss = F.cross_entropy(input, target)\n","loss.backward()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k8vMFfZL4jcZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1593095402024,"user_tz":-540,"elapsed":521,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"eeb64bea-4e10-4b9a-d9a3-c0c7b2eaceb6"},"source":["input"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.3824, -0.9514, -0.5539, -1.1105, -0.6623],\n","        [ 0.4279,  0.1307,  2.1382,  1.0987, -0.8870],\n","        [ 2.0576, -1.8201, -1.3227,  0.3146, -0.8222]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"C0oOG5Tl4rvA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593095409569,"user_tz":-540,"elapsed":628,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"c19efe12-2c0a-44a6-c42d-39196cf04392"},"source":["target"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2, 0, 1])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"hqOP77Be4tvw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593095416164,"user_tz":-540,"elapsed":1053,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"fa217050-ff6e-4389-a7c0-cc71bb88a032"},"source":["loss"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.8968, grad_fn=<NllLossBackward>)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"pPA6RFmLLugP","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m29760hLLuOi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Hz34O1UFinR","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrtUBWcaFiih","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"woSchTbzFh0y","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpWlrJ79bPQa","colab_type":"code","colab":{}},"source":["from itertools import repeat\n","\n","class Sampyo(nn.Module):\n","    def __init__(self):\n","        super(Sampyo, self).__init__()\n","        self.layers = [nn.Linear(2, 2), nn.Linear(2, 2), nn.Linear(2, 2)]\n","        for i, m in enumerate(self.layers):\n","            self.add_module(m.__class__.__name__ + str(i), m)\n","        self.layman = nn.Linear(2, 2)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GDTJ_G1bofr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1592924353610,"user_tz":-540,"elapsed":587,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"b6550529-3759-4d9c-c5c3-185bb9d7c8b1"},"source":["sampyo = Sampyo()\n","for i, m in enumerate(sampyo.named_modules()):\n","    print(i, m)\n","print('==========================================')\n","for i, m in enumerate(sampyo.named_children()):\n","    print(i, m)\n","print('==========================================')\n","for i, m in enumerate(\n","            sampyo._named_members((lambda m: zip(repeat(''), m.layers)),\n","                    recurse=False)):\n","    print(i, m)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 ('', Sampyo(\n","  (layman): Linear(in_features=2, out_features=2, bias=True)\n","))\n","1 ('layman', Linear(in_features=2, out_features=2, bias=True))\n","==========================================\n","0 ('layman', Linear(in_features=2, out_features=2, bias=True))\n","==========================================\n","0 ('', Linear(in_features=2, out_features=2, bias=True))\n","1 ('', Linear(in_features=2, out_features=2, bias=True))\n","2 ('', Linear(in_features=2, out_features=2, bias=True))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cw_A3yx-sLBP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1592924363236,"user_tz":-540,"elapsed":536,"user":{"displayName":"­배정렬","photoUrl":"","userId":"08451514273060784656"}},"outputId":"7cebf008-b80c-47bc-de80-abbba68a1ad0"},"source":["sampyo = Sampyo()\n","for i, m in enumerate(sampyo.named_modules()):\n","    print(i, m)\n","print('==========================================')\n","for i, m in enumerate(sampyo.named_children()):\n","    print(i, m)\n","print('==========================================')\n","for i, m in enumerate(\n","            sampyo._named_members((lambda m: zip(repeat(''), m.layers)),\n","                    recurse=False)):\n","    print(i, m)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 ('', Sampyo(\n","  (Linear0): Linear(in_features=2, out_features=2, bias=True)\n","  (Linear1): Linear(in_features=2, out_features=2, bias=True)\n","  (Linear2): Linear(in_features=2, out_features=2, bias=True)\n","  (layman): Linear(in_features=2, out_features=2, bias=True)\n","))\n","1 ('Linear0', Linear(in_features=2, out_features=2, bias=True))\n","2 ('Linear1', Linear(in_features=2, out_features=2, bias=True))\n","3 ('Linear2', Linear(in_features=2, out_features=2, bias=True))\n","4 ('layman', Linear(in_features=2, out_features=2, bias=True))\n","==========================================\n","0 ('Linear0', Linear(in_features=2, out_features=2, bias=True))\n","1 ('Linear1', Linear(in_features=2, out_features=2, bias=True))\n","2 ('Linear2', Linear(in_features=2, out_features=2, bias=True))\n","3 ('layman', Linear(in_features=2, out_features=2, bias=True))\n","==========================================\n","0 ('', Linear(in_features=2, out_features=2, bias=True))\n","1 ('', Linear(in_features=2, out_features=2, bias=True))\n","2 ('', Linear(in_features=2, out_features=2, bias=True))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pyAGGVBAsNan","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}